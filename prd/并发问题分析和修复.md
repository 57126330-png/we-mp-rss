# 并发问题分析和修复

## 🔍 当前实现分析

### 当前代码逻辑

```python
# jobs/brief.py 第145-157行
for i, article_key in enumerate(article_keys, 1):
    try:
        brief = await self.generate_brief_for_article(article_key)
        # ...
```

**关键发现**：
- ✅ **当前是顺序执行**，不是并发执行
- ✅ 使用 `await` 关键字，每篇文章会等待上一篇完成
- ✅ **不会同时调用多个AI API**

### 执行流程

假设有10篇文章需要生成简报：

```
文章1 → 等待AI响应 → 保存 → 
文章2 → 等待AI响应 → 保存 → 
文章3 → 等待AI响应 → 保存 → 
...
文章10 → 等待AI响应 → 保存
```

**总耗时**：10篇文章 × (AI响应时间 + 保存时间) ≈ 10 × 5秒 = 50秒

## ⚠️ 潜在问题

### 1. 效率问题
- **顺序执行效率低**：如果每篇需要5秒，10篇需要50秒
- **可以优化**：使用并发执行，但需要控制并发数量

### 2. 如果改为并发执行的风险
- **API速率限制**：GLM API可能有QPS限制，并发过高会触发429错误
- **资源占用**：并发过多会占用大量内存和网络连接
- **成本控制**：并发执行可能导致短时间内大量API调用

## ✅ 解决方案：添加可控并发

### 方案：使用信号量（Semaphore）控制并发数量

**优点**：
- ✅ 提高效率（并发执行，而不是顺序执行）
- ✅ 控制并发数量（避免触发API速率限制）
- ✅ 可配置（通过环境变量控制）
- ✅ 安全可靠（不会同时发起大量请求）

**实现**：
- 使用 `asyncio.Semaphore` 限制同时执行的AI API调用数量
- 默认并发数：**2个**（可配置）
- 通过 `AI_BRIEF_MAX_CONCURRENT` 环境变量控制

### 修复后的执行流程

假设有10篇文章，并发数设置为2：

```
时间轴：
0秒  → 文章1开始 | 文章2开始
5秒  → 文章1完成 | 文章2完成 → 文章3开始 | 文章4开始
10秒 → 文章3完成 | 文章4完成 → 文章5开始 | 文章6开始
15秒 → 文章5完成 | 文章6完成 → 文章7开始 | 文章8开始
20秒 → 文章7完成 | 文章8完成 → 文章9开始 | 文章10开始
25秒 → 文章9完成 | 文章10完成
```

**总耗时**：约25秒（相比顺序执行的50秒，效率提升50%）

### 配置说明

```yaml
# config.yaml 或环境变量
ai:
  brief_max_concurrent: 2  # 最大并发数，默认2个
```

**推荐值**：
- **保守**：1-2个（避免速率限制）
- **平衡**：2-3个（推荐）
- **激进**：3-5个（如果API允许，但可能触发速率限制）

### 为什么默认是2个？

1. **避免速率限制**：GLM API可能有QPS限制，并发过高容易触发429错误
2. **资源控制**：并发过多会占用大量内存和网络连接
3. **成本控制**：避免短时间内大量API调用
4. **稳定性**：较低的并发数更稳定可靠

## 📊 性能对比

| 方式 | 10篇文章耗时 | 并发数 | 风险 |
|------|-------------|--------|------|
| 顺序执行（修复前） | ~50秒 | 1 | 无 |
| 并发执行（修复后） | ~25秒 | 2 | 低 |
| 高并发（不推荐） | ~10秒 | 10 | 高（可能触发速率限制） |

## ✅ 修复完成

**已修复**：
- ✅ 添加了并发控制机制
- ✅ 使用信号量限制并发数量
- ✅ 默认2个并发，可配置
- ✅ 保持向后兼容（如果设置为1，就是顺序执行）

**配置项**：
- `AI_BRIEF_MAX_CONCURRENT=2` （环境变量）
- `ai.brief_max_concurrent: 2` （配置文件）

